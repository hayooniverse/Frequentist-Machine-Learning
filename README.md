# Frequentist Machine Learning (ECE475) - Cooper Union  
### Instructor: Prof. Sam Keene  
### Author: Hailey Hayoon Chung  

## ðŸ“Œ Course Overview  
This repository contains my coursework for **Frequentist Machine Learning (ECE475)** at **Cooper Union**, taught by **Prof. Sam Keene**. The projects explore various **statistical and optimization-based machine learning techniques**, with a strong emphasis on frequentist approaches.  

Each project involves data analysis, model implementation, and performance evaluation using **Python**, **pandas**, **NumPy**, **scikit-learn**, and other relevant libraries.  

## ðŸ“‚ Projects Overview  

### **Project 1 â€“ Linear Regression with Gradient Descent**  
**Goal:** Implement and analyze linear regression models using **batch gradient descent** and **stochastic gradient descent (SGD)**.  
- Implemented both **closed-form** and **gradient-based** solutions  
- Analyzed convergence properties and computational efficiency  
- Explored effects of learning rate and feature scaling  

---

### **Project 2 â€“ Logistic Regression & Classification Metrics**  
**Goal:** Implement **logistic regression** for binary classification and evaluate model performance.  
- Derived the **log-likelihood function** and implemented gradient ascent  
- Explored **decision boundaries** and **ROC-AUC curves**  
- Compared logistic regression with **SVMs** and **decision trees**  


---

### **Project 4 â€“ Bayesian Linear Regression vs. Frequentist Approaches**  
**Goal:** Compare **frequentist** and **Bayesian** linear regression methods.  
- Implemented **Maximum Likelihood Estimation (MLE)** and **Maximum A Posteriori (MAP)**  
- Derived Bayesian posterior distributions for model parameters  
- Conducted **uncertainty quantification** and **predictive distributions**  


---

### **Project 5 â€“ Stochastic Gradient Descent (SGD) Analysis**  
**Goal:** Explore the theoretical properties and practical applications of **SGD** in high-dimensional spaces.  
- Analyzed **convergence rates** for convex and non-convex functions  
- Implemented **momentum-based SGD** and **adaptive learning rate techniques**  
- Compared **SGD**, **RMSProp**, and **Adam** optimizers  


---

### **Project 6 â€“ Principal Component Analysis (PCA) & Dimensionality Reduction**  
**Goal:** Implement **PCA** for feature extraction and visualization.  
- Derived **PCA from first principles** using **eigenvalue decomposition**  
- Explored **singular value decomposition (SVD)** for dimensionality reduction  
- Applied PCA to real-world datasets for **data compression** and **visualization**  



---

### **Project 7 â€“ Market Basket Analysis (Association Rules)**  
**Goal:** Perform **association rule mining** using the **Apriori algorithm**.  
- Preprocessed a dataset using **one-hot encoding**  
- Mined **frequent itemsets** and computed **association rules**  
- Analyzed **support**, **confidence**, and **lift** to extract meaningful insights  



